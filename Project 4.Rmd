---
title: "Project 4"
author: "Jean Jimenez, Matthew Roland, & Kelly Eng"
date: "2023-11-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load the required libraries

```{r}
library(tidyverse)
```

# Logistic Regression of Mushroom Dataset

## Introduction

The original Project 4 consisted of going through and processing spam/ not spam emails and labeling them as so. For this project ,we explored the [mushroom dataset](https://archive.ics.uci.edu/dataset/73/mushroom) from UCI Machine Learning Repo. The classification of mushrooms as edible or poisonous is important to public health, culinary arts, and biological research. For project 4, we will try to classify these mushrooms as poisonous or edible using a logistic regression model.

## Data Preprocessing

In the data preprocessing section of the project, several steps were taken to prepare the `mushroom` dataset for logistic regression analysis. First, the dataset was loaded into R for processing. The primary focus was to ensure that the data was 'tidy' and formatted correctly for analysis. This involved converting categorical variables into a suitable numeric format, as many machine learning algorithms, including logistic regression, work better with numerical input.

During this conversion, each category within the variables was assigned a unique numerical identifier. This step is essential to preserve the categorical information in a form that the logistic regression model can utilize effectively. Additionally, the dataset was checked for missing values, and necessary imputations were performed to handle any gaps in the data, ensuring that the model receives a complete dataset for training and testing.

```{r}
# Read the file
url <- "https://raw.githubusercontent.com/Mattr5541/DATA_607_Project-4/main/mushroom/agaricus-lepiota_data.txt"
file = readLines(url)

split_data <- lapply(file, function(x) unlist(strsplit(x, ",")))

# Convert the data to a dataframe
df <- as.data.frame(do.call(rbind, split_data))

# The names of the 23 columns as detailed in agaricus-lepiota_names.txt
col_names = c('class', 'cap_shape', 'cap_surface', 'cap_color', 'bruises', 'odor', 'gill_attachment', 'gill_spacing', 'gill_size', 'gill_color', 'stalk_shape', 'stalk_root', 'stalk_surface_above_ring', 'stalk_surface_below_ring', 'stalk_color_above_ring', 'stalk_color_below_ring', 'veil_type', 'veil_color', 'ring_number', 'ring_type', 'spore_print_color', 'population', 'habitat')

# Assign the names to each column of the dataframe
names(df) <- col_names

# The type of class for each mushroom is binary, poisonous or edible
# There are no missing values for them, so ifelse() can be used
df$class <- ifelse(df$class == 'p', 'poisonous', 'edible')

# These columns also have binary values
df$bruises <- ifelse(df$bruises == 't', 'bruises', 'no')
df$gill_size <- ifelse(df$gill_size == 'b', 'broad', 'narrow')
df$stalk_shape <- ifelse(df$stalk_shape == 'e', 'enlarging', 'tapering')
df$veil_type <- ifelse(df$veil_type == 'p', 'partial', 'universal')

# Rename all the values in each column to make them more clear as noted in agaricus-lepiota_names.txt
# The same file states the only missing values are in the stalk_root column
df <- df |>
  mutate(cap_shape = case_when(
    cap_shape == 'b' ~ 'bell', 
    cap_shape == 'c' ~ 'conical', 
    cap_shape == 'x' ~ 'convex',
    cap_shape == 'f' ~ 'flat',
    cap_shape == 'k' ~ 'knobbed',
    TRUE ~ 'sunken'),
    cap_surface = case_when(
      cap_surface == 'f' ~ 'fibrous',
      cap_surface == 'g' ~ 'grooves',
      cap_surface == 's' ~ 'scaly',
      TRUE ~ 'smooth'
    ),
    cap_color = case_when(
      cap_color == 'n' ~ 'brown',
      cap_color == 'b' ~ 'buff',
      cap_color == 'c' ~ 'cinnamon',
      cap_color == 'g' ~ 'gray',
      cap_color == 'r' ~ 'green',
      cap_color == 'p' ~ 'pink',
      cap_color == 'u' ~ 'purple',
      cap_color == 'e' ~ 'red',
      cap_color == 'w' ~ 'white',
      TRUE ~ 'yellow'
    ),
    odor = case_when(
      odor == 'a' ~ 'almond',
      odor == 'l' ~ 'anise',
      odor == 'c' ~ 'creosote',
      odor == 'y' ~ 'fishy',
      odor == 'f' ~ 'foul',
      odor == 'm' ~ 'musty',
      odor == 'n' ~ 'none',
      odor == 'p' ~ 'pungent',
      TRUE ~ 'spicy'
    ),
    gill_attachment = case_when(
      gill_attachment == 'a' ~ 'attached',
      gill_attachment == 'd' ~ 'descending',
      gill_attachment == 'f' ~ 'free',
      TRUE ~ 'notched'
    ),
    gill_spacing = case_when(
      gill_spacing == 'c' ~ 'close',
      gill_spacing == 'w' ~ 'crowded',
      TRUE ~ 'distant'
    ),
    gill_color = case_when(
      gill_color == 'k' ~ 'black',
      gill_color == 'n' ~ 'brown',
      gill_color == 'b' ~ 'buff',
      gill_color == 'h' ~ 'chocolate',
      gill_color == 'g' ~ 'gray',
      gill_color == 'r' ~ 'green',
      gill_color == 'o' ~ 'orange',
      gill_color == 'p' ~ 'pink',
      gill_color == 'u' ~ 'purple',
      gill_color == 'e' ~ 'red',
      gill_color == 'w' ~ 'white',
      TRUE ~ 'yellow'
    ),
    stalk_root = case_when(
      stalk_root == 'b' ~ 'bulbous',
      stalk_root == 'c' ~ 'club',
      stalk_root == 'u' ~ 'cup',
      stalk_root == 'e' ~ 'equal',
      stalk_root == 'z' ~ 'rhizomorphs',
      stalk_root == 'r' ~ 'rooted',
      TRUE ~ NA
    ),
    stalk_surface_above_ring = case_when(
      stalk_surface_above_ring == 'f' ~ 'fibrous',
      stalk_surface_above_ring == 'y' ~ 'scaly',
      stalk_surface_above_ring == 'k' ~ 'silky',
      TRUE ~ 'smooth'
    ),
    stalk_surface_below_ring = case_when(
      stalk_surface_below_ring == 'f' ~ 'fibrous',
      stalk_surface_below_ring == 'y' ~ 'scaly',
      stalk_surface_below_ring == 'k' ~ 'silky',
      TRUE ~ 'smooth'
      ),
    stalk_color_above_ring = case_when(
      stalk_color_above_ring == 'n' ~ 'brown',
      stalk_color_above_ring == 'b' ~ 'buff',
      stalk_color_above_ring == 'c' ~ 'cinnamon',
      stalk_color_above_ring == 'g' ~ 'gray',
      stalk_color_above_ring == 'o' ~ 'orange',
      stalk_color_above_ring == 'p' ~ 'pink',
      stalk_color_above_ring == 'e' ~ 'red',
      stalk_color_above_ring == 'w' ~ 'white',
      TRUE ~ 'yellow'
    ),
    stalk_color_below_ring = case_when(
      stalk_color_below_ring == 'n' ~ 'brown',
      stalk_color_below_ring == 'b' ~ 'buff',
      stalk_color_below_ring == 'c' ~ 'cinnamon',
      stalk_color_below_ring == 'g' ~ 'gray',
      stalk_color_below_ring == 'o' ~ 'orange',
      stalk_color_below_ring == 'p' ~ 'pink',
      stalk_color_below_ring == 'e' ~ 'red',
      stalk_color_below_ring == 'w' ~ 'white',
      TRUE ~ 'yellow'
    ),
    veil_color = case_when(
      veil_color == 'n' ~ 'brown',
      veil_color == 'o' ~ 'orange',
      veil_color == 'w' ~ 'white',
      TRUE ~ 'yellow'
    ),
    ring_number = case_when(
      ring_number == 'n' ~ '0',
      ring_number == 'o' ~ '1',
      TRUE ~ '2'
    ),
    ring_type = case_when(
      ring_type == 'c' ~ 'cobwebby',
      ring_type == 'e' ~ 'evanescent',
      ring_type == 'f' ~ 'flaring',
      ring_type == 'l' ~ 'large',
      ring_type == 'n' ~ 'none',
      ring_type == 'p' ~ 'pendant',
      ring_type == 's' ~ 'sheathing',
      TRUE ~ 'zone'
    ),
    spore_print_color = case_when(
      spore_print_color == 'k' ~ 'black',
      spore_print_color == 'n' ~ 'brown',
      spore_print_color == 'b' ~ 'buff',
      spore_print_color == 'h' ~ 'chocolate',
      spore_print_color == 'r' ~ 'green',
      spore_print_color == 'o' ~ 'orange',
      spore_print_color == 'u' ~ 'purple',
      spore_print_color == 'w' ~ 'white',
      TRUE ~ 'yellow'
    ),
    population = case_when(
      population == 'a' ~ 'abundant',
      population == 'c' ~ 'clustered',
      population == 'n' ~ 'numerous',
      population == 's' ~ 'scattered',
      population == 'v' ~ 'several',
      TRUE ~ 'solitary'
    ),
    habitat = case_when(
      habitat == 'g' ~ 'grasses',
      habitat == 'l' ~ 'leaves',
      habitat == 'm' ~ 'meadows',
      habitat == 'p' ~ 'paths',
      habitat == 'u' ~ 'urban',
      habitat == 'w' ~ 'waste',
      TRUE ~ 'woods'
    ))

# Convert the number of rings from character to numeric
df$ring_number <- as.numeric(df$ring_number)

# According to agaricus-lepopta_names.txt, there are 2480 missing attributes for the stalk_root column so we can filter those rows out
df <- df |>
  filter(!is.na(stalk_root))

mushroom_colors <- c('brown', 'orange', 'white', 'yellow', 'buff', 'gray', 'pink', 'red', 'green', 'purple', 'cinnamon', 'black', 'chocolate')
surface <- c('fibrous', 'scaly', 'silky', 'smooth')

df_num <- df

df_num$class <- as.numeric(factor(df_num$class, levels=c('poisonous', 'edible')))
df_num$cap_shape <- as.numeric(factor(df_num$cap_shape, levels=c('bell', 'conical', 'convex', 'flat', 'knobbed', 'sunken')))
df_num$cap_surface <- as.numeric(factor(df_num$cap_surface, levels=c('fibrous', 'grooves', 'scaly', 'smooth')))
df_num$cap_color <- as.numeric(factor(df_num$cap_color, levels=mushroom_colors))
df_num$bruises <- as.numeric(factor(df_num$bruises, levels=c('bruises', 'no')))
df_num$odor <- as.numeric(factor(df_num$odor, levels=c('almond', 'anise', 'creosote', 'fishy', 'foul', 'musty', 'none', 'pungent' , 'spicy')))
df_num$gill_attachment <- as.numeric(factor(df_num$gill_attachment, levels=c('attached','descending','free', 'notched')))
df_num$gill_spacing <- as.numeric(factor(df_num$gill_spacing, levels=c('close', 'crowded', 'distant')))
df_num$gill_size <- as.numeric(factor(df_num$gill_size, levels=c('broad', 'narrow')))
df_num$gill_color <- as.numeric(factor(df_num$gill_color, levels=mushroom_colors))
df_num$stalk_shape <- as.numeric(factor(df_num$stalk_shape, levels=c('enlarging', 'tapering')))
df_num$stalk_root <- as.numeric(factor(df_num$stalk_root, levels=c('bulbous', 'club', 'cup', 'equal', 'rhizomorphs', 'rooted')))
df_num$stalk_surface_above_ring <- as.numeric(factor(df_num$stalk_surface_above_ring, levels=surface))
df_num$stalk_surface_below_ring <- as.numeric(factor(df_num$stalk_surface_below_ring, levels=surface))
df_num$stalk_color_above_ring <- as.numeric(factor(df_num$stalk_color_above_ring, levels=mushroom_colors))
df_num$stalk_color_below_ring <- as.numeric(factor(df_num$stalk_color_below_ring, levels=mushroom_colors))
df_num$veil_type <- as.numeric(factor(df_num$veil_type, levels=c('partial', 'universal')))
df_num$veil_color <- as.numeric(factor(df_num$veil_color, levels=mushroom_colors))
df_num$ring_type <- as.numeric(factor(df_num$ring_type, levels=c('cobwebby', 'evanescent', 'flaring', 'large', 'none', 'pendant', 'sheathing', 'zone')))
df_num$spore_print_color <- as.numeric(factor(df_num$spore_print_color, levels=mushroom_colors))
df_num$population <- as.numeric(factor(df_num$population, levels=c('abundant', 'clustered', 'numerous', 'scattered', 'several', 'solitary')))
df_num$habitat <- as.numeric(factor(df_num$habitat, levels=c('grasses', 'leaves', 'meadows', 'paths', 'urban', 'waste', 'woods')))

# Convert the binary columns to zeros and ones
# Veil type is also binary but it only contains partial for all columns, there's not a single row that contains universal for the column
binary_cols <- c(1, 5, 9, 11)
for (col in binary_cols) {
  df_num[[col]] <- df_num[[col]] - 1
}
```

## Exploratory Data Analysis

For exploratory data analysis, a thorough examination of the `mushroom` dataset was conducted to gain insights into its characteristics and uncover any underlying patterns. This involved generating summary statistics; including measures like mean, median, and standard deviation for each variable.

Bar plots were created for the various categorical features such as `ring_number`, `bruises`, `gill_size`, and `stalk_shape`. These visualizations are important in showing the frequency distribution of different categories within each feature. The bar plots also help to visualize the relationship between these categorical features and the target variable (edible or poisonous).

A correlation matrix was made to provide insights into how different features are related to each other.

```{r}
# Summary Statistics
summary(df_num$ring_number)

# Gets the mode for all columns
# The type of mushrooms that appear the most in this dataset are poisonous
df_num |>
  summarise(across(everything(), ~as.numeric(names(which.max(table(.))))))

# The amount of mushrooms with 1 or 2 rings are similar for both poisonous and edible types
# There are no mushrooms that are edible with 0 rings in this dataset
df |>
  ggplot(aes(x = ring_number)) +
  geom_bar() +
  facet_grid(. ~ class) +
  labs(x="Number of Rings", "Count") +
  scale_y_log10()

# Comparing the binary columns

# Poisonous mushrooms tends not to have bruises. Edible mushrooms tend to have more bruises
df |>
  ggplot(aes(x = bruises)) +
  geom_bar() +
  facet_grid(. ~ class) +
  labs(x="Bruises?", "Count") +
  scale_y_log10()

# Both poisonous and edible mushrooms have more broad gill sizes than narrow
df |>
  ggplot(aes(x = gill_size)) +
  geom_bar() +
  facet_grid(. ~ class) +
  labs(x="Type of Gill Size", "Count") +
  scale_y_log10()

# Poisonous mushrooms have more enlarging stalk shape than tapering while the opposite is true for edible mushrooms
df |>
  ggplot(aes(x = stalk_shape)) +
  geom_bar() +
  facet_grid(. ~ class) +
  labs(x="Stalk Shape", "Count") +
  scale_y_log10()
```

## Training Model

### Splitting the Data

We will be performing a simple machine learning procedure, so the next step will be to randomly split the dataset into an 70% / 30% ratio for training and testing, respectively

```{r}
print(cor(df_num[, c(1:23)]))
```

```{r}
#install.packages("caret")
library(caret)

#install.packages("brglm2")
library(brglm2)

#Setting a seed to keep the outcomes consistent
set.seed(12345)

index <- createDataPartition(df_num$class, p = .70, list = F)

train <- df_num[index,]
test <- df_num[-index,]
```

### Training the Model

A logistic regression model was developed to predict whether a mushroom is edible or poisonous based on various features in the dataset. Logistic regression is a popular method for binary classification.

First, we created the logistic regression model, specifying the target variable (edible or poisonous) as a function of the predictor variables. These predictors were `cap_shape`, `cap_color`, `gill_size`, and others. The training dataset, which consisted of 70% of the total data, was used to fit the model. This subset provided a substantial amount of data for the model to learn the patterns and relationships between the features and the target variable.

Once the model was defined and the data was prepared, the next step involved training the model using the `glm()` function in R, specifying the binomial family to denote a logistic regression. During this training phase, the model learned the coefficients for each predictor, adjusting them to best fit the training data.

```{r}

#Function to detect binary columns
# is_bin <- function(train) {
#   binary_col <- sapply(train, function(column) {
#     all(column %in% c(0, 1))
#   })
#   return(binary_col)
# }
# 
# binary_col <- is_bin(train)
# 
# print(binary_col)

str(train)

#The model properly converges when gill size and veil type are removed; but note that a warning is still produced: glm.fit: fitted probabilities numerically 0 or 1 occurred
train_model <- glm(class ~ cap_shape + cap_surface + cap_color + bruises + odor + gill_attachment +
               gill_spacing + gill_color + stalk_shape + stalk_root + 
               stalk_surface_above_ring + stalk_surface_below_ring + 
               stalk_color_above_ring + stalk_color_below_ring + veil_color + ring_number + 
               ring_type + spore_print_color + population + habitat, data = train, family = binomial)


summary(train_model)
```

### Evaluate Training Data

We can now use the model to make predictions on the training data to evaluate its performance.

The results from the confusion matrix and cross-validation provided insights into how well the model was performing. They offered a detailed look at the model's strengths and weaknesses in classifying the mushrooms as edible or poisonous, based on the training data. This evaluation phase was critical for understanding the efficacy of the logistic regression model before proceeding to test it on unseen data.

```{r}
#This code will generate predictions
train_pred <- predict(train_model, type = "response", newdata = train)
train_pred_class <- ifelse(train_pred > 0.5, 1, 0)

#And now we can assess the acuracy of those predictions
confusionMatrix(factor(train_pred_class), factor(train$class))

#As we can see, our training data are able to predict edibility outcomes with a 96% accuracy

#And now we can cross-validate the data
cv_results <- train(class ~ cap_shape + cap_surface + cap_color + bruises + odor + gill_attachment +
               gill_spacing + gill_color + stalk_shape + stalk_root + 
               stalk_surface_above_ring + stalk_surface_below_ring + 
               stalk_color_above_ring + stalk_color_below_ring + veil_color + ring_number + 
               ring_type + spore_print_color + population + habitat, data = train, method = "glm",
               trControl = trainControl(method = "cv", number = 10), family = 'binomial')
print(cv_results)

#As we can see, the RMSE value is low, whereas the R^2 is high, indicating that the model is likely a good fit 
```

-   **Confusion Matrix**:

    -   **True Negatives (1418)**: The model correctly identified 1418 mushrooms as non-poisonous (edible).
    -   **False Positives (60)**: It mistakenly tagged 60 mushrooms as non-poisonous when they were actually poisonous.
    -   **False Negatives (97)**: It incorrectly labeled 97 poisonous mushrooms as edible.
    -   **True Positives (2376)**: And it got it right with 2376 mushrooms, accurately identifying them as poisonous.

-   **Model Performance**:

    -   **Accuracy:** 0.9603 or 96.03%
    -   **95% Confidence Interval:** 0.9537 to 0.9661
    -   **No Information Rate: 0.6166** meaning if we just guessed the most common outcome every time, we'd be right about 61.66% of the time.
    -   **Kappa:** 0.9156
    -   **Sensitivity:** 0.9360 meaning 93.6% of the time, the model correctly identifies poisonous mushrooms.
    -   **Specificity:** 0.9754
    -   **Positive Predictive Value :** 0.9594meaning it predicts a mushroom is edible, it's correct about 95.94% of the time.
    -   **Negative Predictive Value:** 0.9608 which means that when it predicts a mushroom is poisonous, it's correct about 96.08% of the time.

    According to the results, the model is doing a good job at classifying mushrooms as edible or poisonous.

## Predictions for Our Test Data

The test dataset, which comprised 30% of the entire dataset, was used for this purpose. It contained the same features as the training set but had not been used during the model training phase. The model made predictions on this test data, estimating whether each mushroom was edible or poisonous based on the learned patterns from the training data.

```{r}
#This code will apply the model to our test dataset
test_pred <- predict(train_model, type = "response", newdata = test)

test_pred_class <- ifelse(test_pred > 0.5, 1,0)

#This code will check for accuracy
confusionMatrix(factor(test_pred_class), factor(test$class))

##As we can see, the results are rather consistent, with a 95.8% accuracy for predicting edibility

library(pROC)

#The following code will calculate the Area under the Curve
rocCurve <- roc(test$class, test_pred)

plot(rocCurve)
auc(rocCurve)

#The plot and diagnostics demonstrate the high predictive accuracy of our model 
```

-   **Confusion Matrix**:

    -   `True Negatives (0,0)`: 596 - The model correctly predicted 596 instances where mushrooms were not poisonous (edible).
    -   `False Positives (0,1)`: 26 - The model incorrectly predicted 26 instances as non-poisonous (edible) when they were actually poisonous.
    -   `False Negatives (1,0)`: 45 - The model incorrectly predicted 45 instances as poisonous when they were actually non-poisonous (edible).
    -   `True Positives (1,1)`: 1026 - The model correctly predicted 1026 instances where mushrooms were poisonous.

-   **Accuracy**: Our model was correct for 95.81% (0.9581) of the mushrooms in the test set. We are 95% confident that it lies in this range (0.9474, 0.9671).

-   **No Information Rate**: 0.6214.This means if we were to guess the most common class for every mushroom, we'd be right about 62.14% of the time.

-   **P-Value**: \< 2e-16 - This p-value is extremely low. Our model is statistically significant

-   **Kappa**: 0.9104 - Since the kappa is close to one, we know that our model is effective.

-   **Sensitivity and Specificity**:

    -   Sensitivity (True Positive Rate): 0.9298 - About 93% of poisonous mushrooms were correctly identified.
    -   Specificity (True Negative Rate): 0.9753 - About 97.53% of non-poisonous mushrooms were correctly identified.

-   **Predictive Values**:

    -   Positive Predictive Value: 0.9582 - When the model predicts a mushroom is non-poisonous, it is correct about 95.82% of the time.
    -   Negative Predictive Value: 0.9580 - When the model predicts a mushroom is poisonous, it is correct about 95.80% of the time.

-   **Prevalence**: 0.3786 - 37.86% of the mushrooms in the test set were actually non-poisonous (edible).

-   **Detection Rate**: 0.3520 - 35.20% of all mushrooms in the test set were correctly identified as non-poisonous by the model.

-   **Detection Prevalence**: 0.3674 - 36.74% of all mushrooms were predicted as non-poisonous by the model.

-   **Area Under the Curve (AUC)**: 0.9867 - This is very close to 1, meaning the model has good ability to differentiate between edible and poisonous mushrooms.

## Testing

In UCI's Machine Learning Repository, there is a [secondary mushroom dataset](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset) with more data (but new entries). I will import this new data and test the accuracy of our logistic regression model for identifing whether or not mushrooms are poisonous or edible.

### Secondary Mushroom Data Preprocessing

Before we can use our test data, we must prepare it so that it is in the same format of the data used to train our linear model. Since not all columns included in our original model is in the secondary data set, we either have to create columns and estimate the data or train a new model without those columns. We chose to train a new model that will be used to evaluate the new dataset.

```{r}
secondary_dat=read.csv(url("https://raw.githubusercontent.com/Mattr5541/DATA_607_Project-4/main/mushroom/secondary_data.csv"))

names(secondary_dat)

col_names_sec = c('class','cap_diameter', 'cap_shape', 'cap_surface', 'cap_color', 'bruises',  'gill_attachment', 'gill_spacing', 'gill_color', 'stem_height', 'stem_width', 'stem_root', 'stem_surface', 'stem_color', 'veil_type', 'veil_color', 'has_ring', 'ring_type', 'spore_print_color', 'habitat', 'season')

split_data = str_split_fixed(secondary_dat$class.cap.diameter.cap.shape.cap.surface.cap.color.does.bruise.or.bleed.gill.attachment.gill.spacing.gill.color.stem.height.stem.width.stem.root.stem.surface.stem.color.veil.type.veil.color.has.ring.ring.type.spore.print.color.habitat.season, pattern = ";", n = 21) 

test_2_df=as.data.frame(split_data)

names(test_2_df)=col_names_sec



test_2_df$class = as.numeric(factor(test_2_df$class, levels=c('p','e')))

test_2_df$cap_shape = as.numeric(factor(test_2_df$cap_shape, levels=c('b', 'c', 'x', 'f', 'k', 's')))



test_2_df$cap_color = as.numeric(factor(test_2_df$cap_color, levels=c("n","o","w","y","b","g","p","e","r","u","c","k","l")))


test_2_df$bruises = as.numeric(factor(test_2_df$bruises, levels=c('t', 'f')))

test_2_df$gill_attachment = as.numeric(factor(test_2_df$gill_attachment, levels=c('a','d','e', 'f')))


test_2_df$gill_color = as.numeric(factor(test_2_df$gill_color, levels=c("n","o","w","y","b","g","p","e","r","u","c","k","l")))


test_2_df$veil_type = as.numeric(factor(test_2_df$veil_type, levels=c('p', 'u')))


test_2_df$veil_color = as.numeric(factor(test_2_df$veil_color, levels=c("n","o","w","y","b","g","p","e","r","u","c","k","l")))


test_2_df$habitat = as.numeric(factor(test_2_df$habitat, levels=c('g', 'l', 'm', 'p', 'u', 'w', 'd')))








test_2 = test_2_df %>%
  select(c(class,`cap_shape`,`cap_color`,bruises,`gill_attachment`, `gill_color`, `veil_type`,`veil_color`, `habitat`))

train_model_2 = glm(class ~ cap_shape  + cap_color + bruises +  gill_attachment + gill_color +veil_type+ veil_color  + 
                habitat, data = train, family = binomial)


summary(train_model_2)

#generate predictions
train_pred_2 = predict(train_model_2, type = "response", newdata = train)
train_pred_class_2 = ifelse(train_pred_2 > 0.5, 1, 0)

#assess the acuracy of those predictions
confusionMatrix(factor(train_pred_class_2), factor(train$class))

cv_results_2 = train(class ~ cap_shape + cap_color + bruises + odor + gill_attachment + gill_color + veil_color + habitat, data = train, method = "glm",
               trControl = trainControl(method = "cv", number = 10), family = 'binomial')
print(cv_results_2)


```

The second model trained was a less accurate than the first one. But this was expected since the secondary dataset did not the complete set of columns as our original dataset. Lets evaluate this second model on our secondary test data.

confusionMatrix(factor(test_pred_class_2), factor(test_2\$class))

```{r}
test_pred_2 = predict(train_model_2, type = "response", newdata = test_2)


test_pred_class_2 = ifelse(test_pred_2 > 0.5, 2, 1)

test_pred_class_2 = factor(test_pred_class_2, levels = c(1, 2))
test_2$class = factor(test_2$class, levels = c(1, 2))


confusionMatrix(test_pred_class_2, test_2$class)


rocCurve_2 = roc(test_2$class, test_pred_2)

plot(rocCurve_2)
auc(rocCurve_2)
```

1.  **True Positives (2400)**: The model correctly predicted 2400 instances as 'poisonous' mushrooms.

2.  **True Negatives (0)**: The model did not correctly predict any instances of 'edible' mushrooms.

3.  **False Positives (945)**: The model incorrectly classified 945 instances as 'poisonous' , which were actually 'edible'.

4.  **False Negatives (95)**: The model incorrectly classified 95 instances as 'edible', which were actually 'poisonous'.

### Model Performance Metrics

-   **Accuracy (69.77%)**: The model correctly predicted about 70% of the instances. However, this is below the No Information Rate, suggesting that the model might not be performing better than random guessing for this dataset.

-   **Kappa (-0.0528)**: This means that the model is not suitable for this dataset.

-   **Sensitivity (96.19%)**: The model is highly sensitive in predicting poisonous mushrooms but fails significantly in predicting edible mushrooms, as indicated by a specificity of 0%.

-   **Specificity (0%)**: The model fails to correctly identify any true negatives (edible mushrooms)

-   **Positive Predictive Value (71.75%)**: When the model predicts poisonous mushrooms, it is correct about 72% of the time.

Our secondary model was not as accurate for predicting whether the secondary dataset is poisonous or not. In the future, I would consider using more columns and adding the missing values to my new dataset (either by inserting the mean, or individually mushroom by mushroom getting that data point). The more data a model has to train on, the better the model will get ideally.

## Conclusion

In this project, we implemented and evaluated a logistic regression model to classify mushrooms as edible or poisonous,

The logistic regression model, trained on the training set, demonstrated effective learning of the relationships between various mushroom features and their edibility status. The model's performance was initially evaluated on the training data using a confusion matrix and cross-validation, showing promising results.

Our logistic regression model had good results, with high accuracy, sensitivity, and specificity. These outcomes suggest that the model effectively distinguishes between edible and poisonous mushrooms, aligning well with known characteristics of these fungi. Notably, features like odor, gill color, and cap shape have emerged as significant predictors.

There are some results that we should explore in the future. For instance, the model's occasional confusion between certain classes of mushrooms, as evidenced by false positives and negatives, hint at smaller morphological or chemical similarities that aren't captured by the dataset. In the future, we could explore more complex models, like neural networks, to capture complex patterns. Integrating datasets from different geographic and environmental data could enhance the model's applicability to diverse real-world scenarios.
